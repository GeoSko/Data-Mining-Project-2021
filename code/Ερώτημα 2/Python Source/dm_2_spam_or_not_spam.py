# -*- coding: utf-8 -*-
"""DM_2_spam_or_not_spam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jr5doq1zfS1iOLJIjhfrLgHT_Q0lYRUK
"""

# Import Labraries
import pandas as pd
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Activation
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow import keras
from matplotlib import pyplot

# Versions of labraries
import gensim
import keras
import tensorflow
print(f'Tensorflow:{tensorflow.__version__}\nKeras:{keras.__version__}\nGensim:{gensim.__version__}')

df = pd.read_csv('drive/MyDrive/DataMining/spam_or_not_spam/spam_or_not_spam.csv')

df

df['label'].value_counts()

#Check for missing values on email column
df.isnull().sum()

#Print the record with the missing value
df.loc[df.email.isnull()]

# Check for other records with a space on email column
df.loc[df.email == ' ']

# Replace the null value with a space
df.fillna(value= ' ', inplace=True)

df.isnull().sum()

# Tokenize and tag the email text
email_docs = [TaggedDocument(doc.split(' '), [i]) for i, doc in enumerate(df.email)]

# Display the first 10 tagged docs from the list
email_docs[:10]

# Instantiate model
vector_size = 64
doc_model = Doc2Vec(vector_size=vector_size, window=2, min_count=1, workers=8, epochs = 40)

# Build vocab
doc_model.build_vocab(email_docs)

# Train model
doc_model.train(email_docs, total_examples=doc_model.corpus_count, epochs=doc_model.epochs)

# View vocab
# doc_model.wv.vocab

# Generate vectors
email_vectors = [doc_model.infer_vector((df['email'][i].split(' '))) for i in range(0,len(df['email']))]
email_vectors[:2]

# Create a list of lists
dtv= np.array(email_vectors).tolist()
#set list to dataframe column
df['email_vectors'] = dtv
df.head()

# Create model input array and expected output vector
X = email_vectors
y = df['label']

# Tranform array and vector to np array of type float32 to be compatiable with the model
X = np.asarray(X).astype(np.float32)
y = np.asarray(y).astype(np.float32)

X.shape

y.shape

#  Train test split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.25, random_state=42)

# Define keras model
model_0 = Sequential()
model_0.add(Dense(30, input_dim=vector_size, activation='relu'))
model_0.add(Dense(1, activation='sigmoid'))

model_0.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history_0 = model_0.fit(X_train, y_train, epochs=20,
          validation_split=0.2,
          )

# evaluate the model
_, train_acc = model_0.evaluate(X_train, y_train, verbose=0)
_, test_acc = model_0.evaluate(X_test, y_test, verbose=0)

print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))

# plot training accuracy
pyplot.plot(history_0.history['accuracy'], label='train')
pyplot.plot(history_0.history['val_accuracy'], label='validation')
pyplot.legend()
pyplot.title("Training Accuracy")
pyplot.show()

# plot training loss
pyplot.plot(history_0.history['loss'], label='train')
pyplot.plot(history_0.history['val_loss'], label='validation')
pyplot.legend()
pyplot.title("Training Loss")
pyplot.show()

y_pred = model_0.predict (X_test).round()
print(classification_report(y_test, y_pred))



# Define the keras model
model = Sequential()
model.add(Dense(30, input_dim=vector_size, activation='relu'))
model.add(Dense(15, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

#Early stopping monitor
monitor = EarlyStopping(
                        monitor = 'val_loss',
                        min_delta = 1e-3,
                        patience=15,
                        restore_best_weights=True
                        )

model.compile(loss='binary_crossentropy', optimizer="adam", metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=50,
          validation_split=0.2,
          batch_size=32,
          callbacks=[monitor]
          )

_, train_acc = model.evaluate(X_train, y_train, verbose=0)
_, test_acc = model.evaluate(X_test, y_test, verbose=0)
print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))
# plot training history
pyplot.plot(history.history['accuracy'], label='train')
pyplot.plot(history.history['val_accuracy'], label='validation')
pyplot.legend()
pyplot.title("Training Accuracy")
pyplot.show()

# plot training loss
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
pyplot.title("Training Loss")
pyplot.show()

y_pred = model.predict (X_test).round()
print(classification_report(y_test, y_pred))